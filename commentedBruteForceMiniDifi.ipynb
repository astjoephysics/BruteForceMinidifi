{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# import observations of selected objects outputted midway from sorcha\n",
    "# (from PPLinkingFilter.py, save obsv (line 56) to a csv and use that)\n",
    "obs_df = pd.read_csv('/Users/josephmurtagh/Downloads/midobs1000tnos(1).csv')\n",
    "obs_df = obs_df.sort_values(by=['ssObjectId'])\n",
    "obs_df = obs_df.reset_index(drop=True)\n",
    "obs_df['ssObjectId'] = obs_df['ssObjectId'].astype(str)\n",
    "\n",
    "# NEXT TWO BLOCKS ARE SETTING UP ARRAY FOR PROCESSING\n",
    "# convert to record array for sorcha compatability (same process as \n",
    "# PPLinkingFilter employs)\n",
    "nameLen = obs_df['ssObjectId'].str.len().max()\n",
    "obsv = obs_df.to_records(\n",
    "    index=False,\n",
    "    column_dtypes=dict(ssObjectId=f'a{nameLen}', diaSourceId='u8', midPointTai='f8', ra='f8', decl='f8')\n",
    ")\n",
    "\n",
    "# split record array by object\n",
    "i = np.argsort(obsv['ssObjectId'], kind='stable')\n",
    "ssObjects, idx = np.unique(obsv['ssObjectId'][i], return_index=True)\n",
    "objSplits = np.split(i, idx[1:])\n",
    "\n",
    "tracklets = []\n",
    "a=0\n",
    "no = 0\n",
    "\n",
    "# START TRACKLET FINDING LOOP\n",
    "# select one object at a time to see if it gets linked\n",
    "for a in range(len(ssObjects)):\n",
    "    testdf = obs_df.loc[objSplits[a],:]\n",
    "    testdf = testdf.sort_values(by=['midPointTai'])\n",
    "    # display(HTML(testdf.to_html()))\n",
    "\n",
    "    # split by each unique mjd date of observation and put into nights\n",
    "    splits = np.split(testdf['midPointTai'].values, np.where(np.abs(np.diff(testdf['midPointTai'].values)) >= 0.5)[0] + 1) # splitting observation BY NIGHT (e.g. mjd 60514.9 and 60515.1 are the same night)\n",
    "    splitra = np.split(testdf['ra'].values, np.where(np.abs(np.diff(testdf['midPointTai'].values)) >= 0.5)[0] + 1) # split right ascension BY NIGHT\n",
    "    splitdec = np.split(testdf['decl'].values, np.where(np.abs(np.diff(testdf['midPointTai'].values)) >= 0.5)[0] + 1) # split declination BY NIGHT\n",
    "    ras = [list(x) for x in splitra if len(x) > 1] # turn above into lists for manipulation purposes\n",
    "    decs = [list(x) for x in splitdec if len(x) > 1]\n",
    "    nights = [list(x) for x in splits if len(x) > 1]\n",
    "    obspernight = [len(ns) for ns in nights]\n",
    "\n",
    "\n",
    "\n",
    "    # loop over each night and test for tracklets\n",
    "    for n, night in enumerate(nights):\n",
    "        if obspernight[n] < 2: # make sure more than 2 observations in a night\n",
    "            pass\n",
    "        else:\n",
    "            for i in np.arange(len(night)):\n",
    "                for j in np.arange(len(night)):\n",
    "                    if j <= i: # make sure not comparing same night with itself, or night with night in the past\n",
    "                        pass\n",
    "                    else:\n",
    "                        diff = night[j] - night[i]\n",
    "                        if diff >= 0 and diff <= 90/(60*24): # make sure time diff <= 90mins\n",
    "                            coord1 = SkyCoord([ras[n][i]], [decs[n][i]], unit=u.deg) \n",
    "                            coord2 = SkyCoord([ras[n][j]], [decs[n][j]], unit=u.deg)\n",
    "                            sep = coord1.separation(coord2).arcsecond\n",
    "                            if sep >= 0.5: # make sure spatial separation >= 0.5\"\n",
    "                                # append tracklet to list of confirmed found tracklets\n",
    "                                tracklet = dict(\n",
    "                                    no=no,\n",
    "                                    ssObjectId=ssObjects[a],\n",
    "                                    ra1=ras[n][i],\n",
    "                                    dec1=decs[n][i],\n",
    "                                    ra2=ras[n][j],\n",
    "                                    dec2=decs[n][j],\n",
    "                                    mjd1=night[i],\n",
    "                                    mjd2=night[j]\n",
    "                                )\n",
    "                                tracklets.append(tracklet)\n",
    "                                no += 1\n",
    "\n",
    "# create dataframe of found tracklets \n",
    "linkdf = pd.DataFrame(tracklets)\n",
    "\n",
    "# same data preparing step as above\n",
    "nameLen = linkdf['ssObjectId'].str.len().max()\n",
    "links = linkdf.to_records(\n",
    "    index=False,\n",
    "    column_dtypes=dict(no='f8', ssObjectId=f'a{nameLen}', ra1='f8', dec1='f8', ra2='f8', dec2='f8', mjd1='f8', mjd2='f8')\n",
    ")\n",
    "\n",
    "# split record array by object\n",
    "i = np.argsort(links['ssObjectId'], kind='stable')\n",
    "ssObjects, idx = np.unique(links['ssObjectId'][i], return_index=True)\n",
    "objSplits = np.split(i, idx[1:])\n",
    "\n",
    "noLinkages = []\n",
    "links = []\n",
    "\n",
    "# START TRACKLET LINKING LOOP\n",
    "# manually check which tracklet pairs are within 15 days of each other\n",
    "for a in range(len(ssObjects)):\n",
    "    testdf = linkdf.loc[objSplits[a],:]\n",
    "    testdf = testdf.sort_values(by=['mjd1'])\n",
    "    # display(HTML(testdf.to_html()))\n",
    "\n",
    "    # loop over each tracklet now\n",
    "    for n, i in enumerate(np.arange(len(testdf))):\n",
    "        for m, j in enumerate(np.arange(len(testdf))):\n",
    "            if j <= i: # ensure we're not linking self with self or self with temporally past tracklets\n",
    "                pass\n",
    "            else:\n",
    "                diff = testdf.iloc[j,:]['mjd2'] - testdf.iloc[i,:]['mjd1'] # calculate time difference between ith and jth tracklet\n",
    "                if diff > 15: # if the difference is above 15 days, stop finding time differences and use next mjd\n",
    "                    idxs = np.arange(n, m) # create array of indexes of all mjds from ith trackle to jth tracklet\n",
    "                    if idxs.size != 0:\n",
    "                        floors = [np.floor(x) for x in testdf.iloc[idxs,:]['mjd1']] # <-- makes sure that the tracklets are defined on seperate nights to avoid linking 3 tracklets on e.g. nights 1, 5.2, and 5.5\n",
    "                        if len(np.unique(floors)) >= 3: # if there are tracklets on 3 unique nights, append them to a list of confirmed linked tracklets\n",
    "                            links.append(dict(\n",
    "                                ssObjectId=testdf.iloc[i,:]['ssObjectId'],\n",
    "                                ra1=testdf.iloc[i,:]['ra1'],\n",
    "                                dec1=testdf.iloc[i,:]['dec1'],\n",
    "                                ra2=testdf.iloc[j-1,:]['ra2'],\n",
    "                                dec2=testdf.iloc[j-1,:]['dec2'],\n",
    "                                mjd1=testdf.iloc[i,:]['mjd1'],\n",
    "                                mjd2=testdf.iloc[j-1,:]['mjd2']\n",
    "                            ))\n",
    "                    break\n",
    "    \n",
    "\n",
    "# create dataframe of confirmed linked tracklets\n",
    "confirmeddf = pd.DataFrame(links)\n",
    "\n",
    "# same as above two times\n",
    "nameLen = confirmeddf['ssObjectId'].str.len().max()\n",
    "links = confirmeddf.to_records(\n",
    "    index=False,\n",
    "    column_dtypes=dict(no='f8', ssObjectId=f'a{nameLen}', ra1='f8', dec1='f8', ra2='f8', dec2='f8', mjd1='f8', mjd2='f8')\n",
    ")\n",
    "\n",
    "# split record array by object\n",
    "i = np.argsort(links['ssObjectId'], kind='stable')\n",
    "ssObjects, idx = np.unique(links['ssObjectId'][i], return_index=True)\n",
    "objSplits = np.split(i, idx[1:])\n",
    "\n",
    "noLinksPerObj = []\n",
    "\n",
    "# final loop that filters out tracklets such that if there are more than one tracklet on\n",
    "# a given MJD, assume that there is just one single tracklet for that night\n",
    "for a in range(len(ssObjects)):\n",
    "    testdf = confirmeddf.loc[objSplits[a],:]\n",
    "    testdf = testdf.sort_values(by=['mjd1'])\n",
    "    display(HTML(testdf.to_html()))\n",
    "    noLinksPerObj.append(len(np.unique(np.floor(testdf['mjd1'].values)))) # this is the step that does it, floor the mjd date and then find the length of unique mjds \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display each object and the number of brute force linked tracklets it has\n",
    "bruteDF = pd.DataFrame({'objs':ssObjects, 'links':noLinksPerObj})\n",
    "bruteDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicted number of links from miniDifi output (4th column of each row of obj = linkObservations(...) \n",
    "# from PPLinkingFilter)\n",
    "minidifiLinks = pd.read_csv('/Users/josephmurtagh/Documents/PhD/minidifi/sorcha_minidifi/noLinks.csv', header=None)\n",
    "minidifiObjs = pd.read_csv('/Users/josephmurtagh/Documents/PhD/minidifi/sorcha_minidifi/objs.csv')\n",
    "minidifiDF = pd.DataFrame({'objs':minidifiObjs['0'], 'links':minidifiLinks[0]})\n",
    "minidifiDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
